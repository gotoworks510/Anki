"""
LLM APIçµ±åˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
å®Ÿéš›ã®LLM APIã¨çµ±åˆã™ã‚‹ãŸã‚ã®æ‹¡å¼µä¾‹
"""

import os
import json
from typing import Dict, List, Optional
from llm_interface import LearningSession

class LLMIntegratedSession(LearningSession):
    """å®Ÿéš›ã®LLM APIã¨çµ±åˆã—ãŸå­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³"""
    
    def __init__(self, deck_name: str = "LLMå­¦ç¿’", llm_provider: str = "openai"):
        super().__init__(deck_name)
        self.llm_provider = llm_provider
        self.setup_llm()
    
    def setup_llm(self):
        """LLM APIã®è¨­å®š"""
        if self.llm_provider == "openai":
            # OpenAI APIè¨­å®šä¾‹
            self.api_key = os.getenv("OPENAI_API_KEY")
            if not self.api_key:
                print("âš ï¸  OPENAI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print("ğŸ“ export OPENAI_API_KEY='your-api-key' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
        
        elif self.llm_provider == "claude":
            # Claude APIè¨­å®šä¾‹
            self.api_key = os.getenv("ANTHROPIC_API_KEY")
            if not self.api_key:
                print("âš ï¸  ANTHROPIC_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
                print("ğŸ“ export ANTHROPIC_API_KEY='your-api-key' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")
    
    def call_llm_api(self, question: str, context: str = "") -> str:
        """LLM APIã‚’å‘¼ã³å‡ºã—ã¦å›ç­”ã‚’ç”Ÿæˆ"""
        
        # å­¦ç¿’ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        prompt = f"""
ã‚ãªãŸã¯å„ªç§€ãªæ•™å¸«ã§ã™ã€‚ä»¥ä¸‹ã®è³ªå•ã«å¯¾ã—ã¦ã€Ankiã‚«ãƒ¼ãƒ‰å­¦ç¿’ã«é©ã—ãŸå½¢ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

å›ç­”ã®è¦ä»¶ï¼š
1. æ˜ç¢ºã§ç°¡æ½”ãªèª¬æ˜
2. é‡è¦ãªãƒã‚¤ãƒ³ãƒˆã¯ç®‡æ¡æ›¸ãã§æ•´ç†
3. å°‚é–€ç”¨èªã¯å®šç¾©ã‚‚å«ã‚ã¦èª¬æ˜
4. å®Ÿä¾‹ã‚„æ¯”è¼ƒãŒã‚ã‚Œã°å«ã‚ã‚‹
5. æ®µéšçš„ãªæ‰‹é †ãŒã‚ã‚‹å ´åˆã¯ç•ªå·ä»˜ãã§æ•´ç†

è³ªå•: {question}

{context and f"è¿½åŠ ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {context}" or ""}

å›ç­”:"""
        
        if self.llm_provider == "openai":
            return self._call_openai_api(prompt)
        elif self.llm_provider == "claude":
            return self._call_claude_api(prompt)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›ç­”
            return self._generate_simulated_answer(question, "")
    
    def _call_openai_api(self, prompt: str) -> str:
        """OpenAI APIå‘¼ã³å‡ºã—ï¼ˆå®Ÿè£…ä¾‹ï¼‰"""
        try:
            # import openai  # pip install openai
            # 
            # response = openai.ChatCompletion.create(
            #     model="gpt-3.5-turbo",
            #     messages=[
            #         {"role": "system", "content": "ã‚ãªãŸã¯å„ªç§€ãªæ•™å¸«ã§ã™ã€‚"},
            #         {"role": "user", "content": prompt}
            #     ],
            #     max_tokens=1000,
            #     temperature=0.7
            # )
            # return response.choices[0].message.content
            
            # å®Ÿè£…ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            return "OpenAI APIã¨ã®çµ±åˆãŒå¿…è¦ã§ã™ã€‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
            
        except Exception as e:
            print(f"âŒ OpenAI APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_simulated_answer(prompt, "")
    
    def _call_claude_api(self, prompt: str) -> str:
        """Claude APIå‘¼ã³å‡ºã—ï¼ˆå®Ÿè£…ä¾‹ï¼‰"""
        try:
            # import anthropic  # pip install anthropic
            # 
            # client = anthropic.Anthropic(api_key=self.api_key)
            # response = client.messages.create(
            #     model="claude-3-sonnet-20240229",
            #     max_tokens=1000,
            #     messages=[
            #         {"role": "user", "content": prompt}
            #     ]
            # )
            # return response.content[0].text
            
            # å®Ÿè£…ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
            return "Claude APIã¨ã®çµ±åˆãŒå¿…è¦ã§ã™ã€‚ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚"
            
        except Exception as e:
            print(f"âŒ Claude APIå‘¼ã³å‡ºã—ã‚¨ãƒ©ãƒ¼: {e}")
            return self._generate_simulated_answer(prompt, "")
    
    def smart_learning_session(self):
        """ã‚¹ãƒãƒ¼ãƒˆãªå­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³ï¼ˆAIå›ç­”ä»˜ãï¼‰"""
        print("ğŸ¤– AIçµ±åˆå­¦ç¿’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’é–‹å§‹ã—ã¾ã™")
        print("ğŸ“ å®Ÿéš›ã®LLMãŒå›ç­”ã‚’ç”Ÿæˆã—ã¾ã™")
        print("ğŸ’¡ ãƒˆãƒ”ãƒƒã‚¯ã‚’æ˜ç¢ºã«æŒ‡å®šã™ã‚‹ã¨ã€ã‚ˆã‚Šè‰¯ã„å›ç­”ãŒå¾—ã‚‰ã‚Œã¾ã™")
        print("-" * 60)
        
        while True:
            try:
                user_input = input("\nğŸ¤” è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'çµ‚äº†', 'q']:
                    break
                
                if not user_input:
                    continue
                
                # ãƒˆãƒ”ãƒƒã‚¯ã¨è³ªå•ã‚’åˆ†é›¢
                topic = ""
                question = user_input
                context = ""
                
                if user_input.startswith('[') and ']' in user_input:
                    parts = user_input.split(']', 1)
                    if len(parts) == 2:
                        topic = parts[0][1:].strip()
                        question = parts[1].strip()
                        context = f"ã“ã®è³ªå•ã¯{topic}ã«é–¢ã™ã‚‹ã‚‚ã®ã§ã™ã€‚"
                
                print(f"\nğŸ¤– LLMã«å•ã„åˆã‚ã›ä¸­...")
                
                # å®Ÿéš›ã®LLM APIã‚’å‘¼ã³å‡ºã—
                llm_answer = self.call_llm_api(question, context)
                
                print(f"\nğŸ’¡ LLMå›ç­”:\n{llm_answer}")
                
                # ã‚«ãƒ¼ãƒ‰ç”Ÿæˆã®ç¢ºèª
                confirm = input("\nâ“ ã“ã®å›ç­”ã‹ã‚‰Ankiã‚«ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ã¾ã™ã‹ï¼Ÿ (y/n): ").strip().lower()
                
                if confirm in ['y', 'yes', 'ã¯ã„', 'h']:
                    result = self.process_qa_pair(question, llm_answer, topic)
                    
                    print(f"\nğŸ“Š çµæœ:")
                    print(f"   ç”Ÿæˆã•ã‚ŒãŸã‚«ãƒ¼ãƒ‰: {result['cards_generated']}æš")
                    print(f"   è¿½åŠ ã•ã‚ŒãŸã‚«ãƒ¼ãƒ‰: {result['cards_added']}æš")
                    if result['cards_failed'] > 0:
                        print(f"   å¤±æ•—ã—ãŸã‚«ãƒ¼ãƒ‰: {result['cards_failed']}æš")
                    
                    # ç”Ÿæˆã•ã‚ŒãŸã‚«ãƒ¼ãƒ‰ã®æ¦‚è¦ã‚’è¡¨ç¤º
                    if result['successful_cards']:
                        print(f"\nğŸ“‹ è¿½åŠ ã•ã‚ŒãŸã‚«ãƒ¼ãƒ‰:")
                        for i, card_front in enumerate(result['successful_cards'][:3], 1):
                            print(f"   {i}. {card_front[:50]}...")
                        if len(result['successful_cards']) > 3:
                            print(f"   ... ä»–{len(result['successful_cards'])-3}æš")
                
            except KeyboardInterrupt:
                break
            except Exception as e:
                print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        
        self.show_session_summary()

def create_study_plan(subjects: List[str], session_name: str = "å­¦ç¿’è¨ˆç”»") -> Dict:
    """ä½“ç³»çš„ãªå­¦ç¿’è¨ˆç”»ã®ä½œæˆ"""
    
    study_plan = {
        "session_name": session_name,
        "subjects": {},
        "total_questions": 0
    }
    
    for subject in subjects:
        questions = []
        print(f"\nğŸ“š {subject}ã®å­¦ç¿’å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        print("ğŸ’¡ 'done'ã¨å…¥åŠ›ã™ã‚‹ã¨æ¬¡ã®ç§‘ç›®ã«é€²ã¿ã¾ã™")
        
        while True:
            question = input(f"[{subject}] è³ªå•: ").strip()
            if question.lower() == 'done':
                break
            if question:
                questions.append(f"[{subject}] {question}")
        
        study_plan["subjects"][subject] = questions
        study_plan["total_questions"] += len(questions)
    
    return study_plan

def execute_study_plan(study_plan: Dict, deck_name: str = None):
    """å­¦ç¿’è¨ˆç”»ã®å®Ÿè¡Œ"""
    
    if not deck_name:
        deck_name = study_plan["session_name"]
    
    session = LLMIntegratedSession(deck_name)
    
    print(f"\nğŸ¯ å­¦ç¿’è¨ˆç”»'{study_plan['session_name']}'ã‚’å®Ÿè¡Œã—ã¾ã™")
    print(f"ğŸ“Š ç·è³ªå•æ•°: {study_plan['total_questions']}ä»¶")
    
    total_cards = 0
    
    for subject, questions in study_plan["subjects"].items():
        print(f"\nğŸ“– {subject} ({len(questions)}ä»¶ã®è³ªå•)")
        
        for i, question in enumerate(questions, 1):
            print(f"\n[{i}/{len(questions)}] {question}")
            
            # å®Ÿéš›ã®LLMã‚’å‘¼ã³å‡ºã—
            answer = session.call_llm_api(question)
            print(f"å›ç­”: {answer[:100]}...")
            
            # è‡ªå‹•ã§ã‚«ãƒ¼ãƒ‰ç”Ÿæˆ
            result = session.process_qa_pair(question, answer, subject)
            total_cards += result['cards_added']
    
    print(f"\nğŸ‰ å­¦ç¿’è¨ˆç”»å®Œäº†!")
    print(f"ğŸ“Š ç·ç”Ÿæˆã‚«ãƒ¼ãƒ‰æ•°: {total_cards}æš")
    session.show_session_summary()

# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    print("ğŸš€ LLMçµ±åˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ")
    
    mode = input("ãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠã—ã¦ãã ã•ã„ (1: å¯¾è©±å­¦ç¿’, 2: å­¦ç¿’è¨ˆç”»ä½œæˆ): ")
    
    if mode == "1":
        # å¯¾è©±å­¦ç¿’ãƒ¢ãƒ¼ãƒ‰
        session = LLMIntegratedSession("AIå­¦ç¿’")
        session.smart_learning_session()
        
    elif mode == "2":
        # å­¦ç¿’è¨ˆç”»ãƒ¢ãƒ¼ãƒ‰
        subjects = input("å­¦ç¿’ç§‘ç›®ã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã§å…¥åŠ›: ").split(",")
        subjects = [s.strip() for s in subjects if s.strip()]
        
        plan = create_study_plan(subjects)
        
        execute = input("ã“ã®å­¦ç¿’è¨ˆç”»ã‚’å®Ÿè¡Œã—ã¾ã™ã‹ï¼Ÿ (y/n): ")
        if execute.lower() in ['y', 'yes']:
            execute_study_plan(plan)
    
    else:
        print("ãƒ‡ãƒ¢ãƒ¢ãƒ¼ãƒ‰ã§å®Ÿè¡Œã—ã¾ã™")
        session = LLMIntegratedSession("ãƒ‡ãƒ¢")
        session.smart_learning_session()